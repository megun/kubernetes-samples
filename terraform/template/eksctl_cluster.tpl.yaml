apiVersion: eksctl.io/v1alpha5
kind: ClusterConfig

metadata:
  name: ${eks_cluster_name}
  region: ${eks_cluster_region}
  version: "1.14"

vpc:
  subnets:
    private:
      ap-northeast-1a: { id: ${private_subnet_id_0} }
      ap-northeast-1c: { id: ${private_subnet_id_1} }
      ap-northeast-1d: { id: ${private_subnet_id_2} }
    public:
      ap-northeast-1a: { id: ${public_subnet_id_0} }
      ap-northeast-1c: { id: ${public_subnet_id_1} }
      ap-northeast-1d: { id: ${public_subnet_id_2} }  

#cloudWatch:
#  clusterLogging:
#    enableTypes:
#      - "api"
#      - "audit"
#      - "authenticator"
#      - "controllerManager"
#      - "scheduler"

iam:
  withOIDC: true
#  serviceAccounts:
#  - metadata:
#      name: alb-ingress-controller
#      namespace: kube-system
#    attachPolicyARNs:
#    - "arn:aws:iam::111111111111:policy/alb-ingress-controller"
#  - metadata:
#      name: external-dns
#      namespace: kube-system
#    attachPolicyARNs:
#    - "arn:aws:iam::111111111111:policy/external-dns"
#  - metadata:
#      name: cluster-autoscaler
#      namespace: kube-system
#      labels:
#        k8s-addon: cluster-autoscaler.addons.k8s.io
#        k8s-app: cluster-autoscaler
#    attachPolicyARNs:
#    - "arn:aws:iam::111111111111:policy/cluster-autoscaler"
#  - metadata:
#      name: s3-reader
#      # if no namespace is set, "default" will be used;
#      # the namespace will be created if it doesn't exist already
#      namespace: backend-apps
#      labels: {aws-usage: "application"}
#    attachPolicyARNs:
#    - "arn:aws:iam::aws:policy/AmazonS3ReadOnlyAccess"
#  - metadata:
#      name: cache-access
#      namespace: backend-apps
#      labels: {aws-usage: "application"}
#    attachPolicyARNs:
#    - "arn:aws:iam::aws:policy/AmazonDynamoDBReadOnlyAccess"
#    - "arn:aws:iam::aws:policy/AmazonElastiCacheFullAccess"
#  - metadata:
#      name: cluster-autoscaler
#      namespace: kube-system
#      labels: {aws-usage: "cluster-ops"}
#    attachPolicy: # inline policy can be defined along with `attachPolicyARNs`
#      Version: "2012-10-17"
#      Statement:
#      - Effect: Allow
#        Action:
#        - "autoscaling:DescribeAutoScalingGroups"
#        - "autoscaling:DescribeAutoScalingInstances"
#        - "autoscaling:DescribeLaunchConfigurations"
#        - "autoscaling:DescribeTags"
#        - "autoscaling:SetDesiredCapacity"
#        - "autoscaling:TerminateInstanceInAutoScalingGroup"
#        - "ec2:DescribeLaunchTemplateVersions"
#        Resource: '*'

nodeGroups:
  - name: ng-1-workers
    labels: { role: workers }
    desiredCapacity: 2
    minSize: 2
    maxSize: 5
    instancesDistribution:
      #maxPrice: 0.017
      instanceTypes: ["t3.large", "t3.medium"]
      onDemandBaseCapacity: 0
      onDemandPercentageAboveBaseCapacity: 0
      spotInstancePools: 2
    privateNetworking: true
    securityGroups:
      withShared: true
      withLocal: true
      attachIDs: [${worker_node_securitygroups}]
    iam:
      instanceProfileARN: "${instance_profile_arn_worker}"
      instanceRoleARN: "${instance_role_arn_worker}"
    preBootstrapCommands:
      - "yum install -y https://s3.amazonaws.com/ec2-downloads-windows/SSMAgent/latest/linux_amd64/amazon-ssm-agent.rpm"
    tags:
      k8s.io/cluster-autoscaler/${eks_cluster_name}: owned
      k8s.io/cluster-autoscaler/enabled: "true"

  #- name: ng-2-builders
  #  labels: { role: builders }
  #  instanceType: t3.medium
  #  desiredCapacity: 2
  #  privateNetworking: true
  #  iam:
  #    withAddonPolicies:
  #      imageBuilder: true
  #  tags:
  #    tag1: val1
  #    tag2: val2

#managedNodeGroups:
#  - name: managed-ng-1
#    minSize: 2
#    maxSize: 4
#    desiredCapacity: 3
#    volumeSize: 20
#    ssh:
#      allow: true
#      publicKeyPath: ~/.ssh/id_rsa.pub
#      # new feature for restricting SSH access to certain AWS security group IDs
#      sourceSecurityGroupIds: ["sg-059ea2deae09f85e6"]
#    labels: {role: worker}
#    tags:
#      nodegroup-role: worker

#fargateProfiles:
#  - name: fp-default
#    selectors:
#      # All workloads in the "default" Kubernetes namespace will be
#      # scheduled onto Fargate:
#      - namespace: default
#      # All workloads in the "kube-system" Kubernetes namespace will be
#      # scheduled onto Fargate:
#      - namespace: kube-system
#  - name: fp-dev
#    selectors:
#      # All workloads in the "dev" Kubernetes namespace matching the following
#      # label selectors will be scheduled onto Fargate:
#      - namespace: dev
#        labels:
#          env: dev
#          checks: passed